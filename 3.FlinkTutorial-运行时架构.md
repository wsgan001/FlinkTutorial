### 3. 运行时架构

---

#### 运行时组件

- JobManager

    - 控制应用程序的主进程
    - 接收作业图(JobGraph)、逻辑数据流图(Logical Dataflow Graph)和打包了所有类库和其他资源的jar
    - 将JobGraph转换为物理层面的数据流图叫做执行图(Execution Graph)，包含所有可以并发执行的任务
    - 向资源管理器请求执行任务必要的资源
    - 运行中负责所有需要中央协调的操作比如checkpoint

- TaskManager

    - 每个TaskManager包含了一定数量的Slots
    - Slots数量限制了TaskManager能执行的任务数量
    - 启动后向ResourceManager注册它的Slots
    - JobManager通过向ResourceManager申请，从而使用Slots
    - 执行过程中TaskManager可以跟其他运行同一应用程序的TaskManager交换数据

- ResourceManager

    - 管理集群资源，slots
    - 包含多种ResourceManager，如Yarn、Mesos、K8S以及Standalone部署
    - 当JobManager申请资源时，充足则直接分配，否则向资源提供平台发起会话申请资源

- Dispatcher

    - 提供restful接口，方便任务提交等
    - 一个应用提交执行时，分发器会启动并将应用移交给JobManager
    - 启动WebUI
    - 不是一定存在的，取决于应用提交运行的方式

#### 任务提交流程

    1. 客户端向Dispatcher提交应用
    2. Dispatcher启动并向JobManager提交应用
    3. JobManager向ResourceManager申请slots
    4. TaskManager启动并向ResourceManager注册自己的slots
    5. ResourceManager向TaskManager发出提供slot的指令
    6. TaskManager提供Slots
    7. JobManager提交要在slots中执行的任务
    8. TaskManager间交互数据

#### 任务提交流程(Yarn Per-Job)

    1. Flink Client上传Flink的jar和配置到HDFS
    2. Flink Client提交Job到ResourceManager(Yarn的)
    3. ResourceManager启动ApplicationMaster(包括NodeManager和JobManager)
    4. JobManager向ResourceManager申请资源
    5. JobManager启动NodeManager(TaskManager)


#### 任务调度原理

1. 解析代码，根据代码执行流程生成逻辑上的数据流图，客户端把数据流图做简单的调整，把可以合并的任务合并在一起，合并后的数据流图叫做JobGraph
2. 将JobGraph和应用的jar等提交给JobManager，JobManager分析JobGraph，判断到底需要多少slots，怎样分配和执行任务，然后将任务分发给TaskManager，JobManager发送指令包括部署任务、停止任务、触发Checkpoint等
3. TaskManager向JobManager汇报任务状态、心跳和统计信息等。TaskManager之间进行数据的交互

##### 并行度

一个特定算子的子任务的个数被称为其并行度，一般情况下，一个stream的并行度可以认为就是其所有算子中最大的并行度

##### TaskManager和Slots

Flink中每一个TaskManager都是一个JVM进程，它可能会在独立的线程上执行一个或多个子任务

为了控制一个TaskManager能接收多少个task，TaskManager通过task slot来进行控制，一个TaskManager至少有一个slot。(slot只对内存进行隔离，不对CPU进行隔离)

##### Slot共享

默认情况下，Flink允许子任务共享slot，即使它们是不同任务的子任务。结果是，一个slot可以保存作业的整个管道。(因为对于同一条数据，同一时刻只能被一个slot处理，所以有了这个能力，数据也不必大量的交换)

Task slot是静态概念，是指TaskManager具有的并发执行能力。

##### 并行子任务的分配

算子的最大并行度是多少，就必须有多少个slot

并行度小于最大并行度的任务指派，可以配置指派策略 

##### Slot共享实例

##### 执行图和任务链

程序与数据流

所有的Flink程序由三部分组成: Source、Transformation和Sink

Source负责读取数据、Transformation使用各种算子进行处理加工，Sink负责输出

在运行时，Flink上运行的程序会被映射成"逻辑数据流"(dataflows)，它包含了三部分

每一个dataflow以一个或多个sources开始，以一个或多个sink结束。dataflow类似一个有向无环图

在大部分情况下，程序中的转换算子跟dataflow中的算子是一一对应的

##### 执行图

- Flink中的执行图可以分为四层: StreamGraph -> JobGraph -> ExecutionGraph -> 物理执行图
- StreamGraph: 根据用户通过StreamAPI编写的代码生成的最初的图，用于表示程序的拓扑结构
- JobGraph: StreamGraph经过优化(符合条件的节点chain在一起作为一个节点)生成JobGraph，是提交给JobManager的数据结构
- ExecutionGraph: JobManager根据JobGraph生成的，是JobGraph的并行化版本，是调度层核心的数据结构
- 物理执行图: JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的图，并不是一个具体的数据结构

##### 数据传输形式

一个程序中，不同算子的并行度可能是不同的。算子间数据传输有以下方式

- One-to-One: Stream维护着分区以及元素的顺序(比如source和map间)，意味着map算子的子任务看到的元素的个数以及顺序跟source算子的子任务生产的元素的个数顺序相同。map、filter、flatMap都是One-to-One的
- Redistributing: stream的分区会发生变化，每个算子的子任务根据选择的transformation发送数据到不同的目标任务。如keyBy根据hashCode充分区，broadcast和rebalance随机重新分区

##### 任务链

- Flink采用一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将两个或多个算子设为相同的并行度，并通过本地转发的方式进行连接
- 相同并行度的one-to-one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子成为里面的subtask
- 并行度相同、one-to-one操作。二者缺一不可 

#### 自定义任务调度规则

- disableChaining() 当前任务不合并入任务链，前后都需要断开
- startNewChain() 开启一个新任务链, 但前面需要断开
- slotSharingGroup() 算子调用该方法后，后面的算子使用单独的slot共享组，在同一个共享组内的算子可以共享slot
- env.disableOperatorChaining() 全局切断任务链